{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3490029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "\n",
    "# Set up Faker for generating random data\n",
    "fake = Faker()\n",
    "\n",
    "# List of provinces\n",
    "provinces = [\n",
    "    \"Alberta\", \"British Columbia\", \"Manitoba\", \"New Brunswick\",\n",
    "    \"Newfoundland and Labrador\", \"Nova Scotia\", \"Ontario\",\n",
    "    \"Prince Edward Island\", \"Quebec\", \"Saskatchewan\"\n",
    "]\n",
    "\n",
    "# Function to generate a random date within the past one year\n",
    "def random_date_within_past_year():\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=365)\n",
    "    random_days = random.randint(0, 365)\n",
    "    return start_date + timedelta(days=random_days)\n",
    "\n",
    "# Function to generate data for a large table and save it in chunks\n",
    "def generate_large_table(file_path, num_rows, header, valid_ids=None):\n",
    "    chunk_size = 10000  # You can adjust this value based on your system's memory capacity\n",
    "    num_chunks = num_rows // chunk_size\n",
    "\n",
    "    with open(file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "\n",
    "        for _ in range(num_chunks):\n",
    "            rows = []\n",
    "            for _ in range(chunk_size):\n",
    "                row_data = [fake.uuid4()]\n",
    "                if valid_ids:\n",
    "                    row_data.extend(random.sample(valid_ids, len(header) - 1))\n",
    "                else:\n",
    "                    row_data.extend(generate_random_data(len(header) - 1))\n",
    "                rows.append(row_data)\n",
    "\n",
    "            writer.writerows(rows)\n",
    "\n",
    "        remaining_rows = num_rows % chunk_size\n",
    "        if remaining_rows > 0:\n",
    "            rows = []\n",
    "            for _ in range(remaining_rows):\n",
    "                row_data = [fake.uuid4()]\n",
    "                if valid_ids:\n",
    "                    row_data.extend(random.sample(valid_ids, len(header) - 1))\n",
    "                else:\n",
    "                    row_data.extend(generate_random_data(len(header) - 1))\n",
    "                rows.append(row_data)\n",
    "\n",
    "            writer.writerows(rows)\n",
    "\n",
    "def generate_random_data(num_columns):\n",
    "    return [fake.name() for _ in range(num_columns)]\n",
    "\n",
    "# Generating a large table with 100 MB of data\n",
    "num_rows = 20000  # Change this value to adjust the number of rows\n",
    "\n",
    "# Generate data for the Order table\n",
    "table1_header = ['orderId', 'Date', 'Amount']\n",
    "table1_data = {\n",
    "    'orderId': [fake.uuid4() for _ in range(num_rows)],\n",
    "    'Date': [random_date_within_past_year() for _ in range(num_rows)],\n",
    "    'Amount': [random.uniform(10, 1000) for _ in range(num_rows)]\n",
    "}\n",
    "table1_df = pd.DataFrame(table1_data)\n",
    "\n",
    "# Generate data for the Orders table\n",
    "valid_order_ids = table1_df['orderId'].to_list()\n",
    "table2_header = ['orderId', 'CustomerId', 'SalesId']\n",
    "table2_data = {\n",
    "    'orderId': random.choices(valid_order_ids, k=num_rows),\n",
    "    'CustomerId': [fake.uuid4() for _ in range(num_rows)],\n",
    "    'SalesId': [fake.uuid4() for _ in range(num_rows)]\n",
    "}\n",
    "table2_df = pd.DataFrame(table2_data)\n",
    "\n",
    "# Generate data for the Customer table\n",
    "valid_customer_ids = table2_df['CustomerId'].to_list()\n",
    "table3_header = ['CustomerId', 'Name', 'Province', 'Age']\n",
    "table3_data = {\n",
    "    'CustomerId': valid_customer_ids,\n",
    "    'Name': [fake.name() for _ in range(num_rows)],\n",
    "    'Province': [random.choice(provinces) for _ in range(num_rows)],\n",
    "    'Age': [random.randint(18, 80) for _ in range(num_rows)]\n",
    "}\n",
    "table3_df = pd.DataFrame(table3_data)\n",
    "\n",
    "# Generate data for the Salesman table\n",
    "valid_sales_ids = table2_df['SalesId'].to_list()\n",
    "table4_header = ['SalesId', 'Name', 'Province', 'Age']\n",
    "table4_data = {\n",
    "    'SalesId': valid_sales_ids,\n",
    "    'Name': [fake.name() for _ in range(num_rows)],\n",
    "    'Province': [random.choice(provinces) for _ in range(num_rows)],\n",
    "    'Age': [random.randint(25, 65) for _ in range(num_rows)]\n",
    "}\n",
    "table4_df = pd.DataFrame(table4_data)\n",
    "\n",
    "# Save the tables as CSV files\n",
    "table1_df.to_csv('Order.csv', index=False)\n",
    "table2_df.to_csv('Orders.csv', index=False)\n",
    "table3_df.to_csv('Customer.csv', index=False)\n",
    "table4_df.to_csv('Salesman.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76673df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57a6111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
